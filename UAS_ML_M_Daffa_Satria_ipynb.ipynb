{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq1b6CEFQilV6/y1sBbNe/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhdaffas/UAS-ML/blob/main/UAS_ML_M_Daffa_Satria_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1yM1mv6LMIN",
        "outputId": "6dca8bd3-9eb7-47a8-d305-e446a2e76d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.2265e-37])\n",
            "tensor([1.6816e-34, 0.0000e+00, 1.6815e-34])\n",
            "tensor([[1.6821e-34, 0.0000e+00, 1.6819e-34],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
            "tensor([[[1.6815e-34, 0.0000e+00, 1.5735e-34],\n",
            "         [0.0000e+00, 1.1210e-43, 0.0000e+00]],\n",
            "\n",
            "        [[1.5695e-43, 0.0000e+00, 0.0000e+00],\n",
            "         [0.0000e+00, 1.3556e-19, 1.3563e-19]]])\n",
            "tensor([[0.3721, 0.8595, 0.8741],\n",
            "        [0.5533, 0.2258, 0.3819],\n",
            "        [0.3522, 0.2433, 0.4487],\n",
            "        [0.6858, 0.8014, 0.7201],\n",
            "        [0.9223, 0.5056, 0.8225]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.Size([5, 3])\n",
            "torch.float32\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n",
            "torch.Size([2])\n",
            "tensor([[0.6840, 0.0161, 0.4506],\n",
            "        [0.3361, 0.1204, 0.1060],\n",
            "        [0.2456, 0.7636, 0.9184],\n",
            "        [0.1373, 0.0071, 0.3609],\n",
            "        [0.1721, 0.1589, 0.4985]])\n",
            "tensor([0.6840, 0.3361, 0.2456, 0.1373, 0.1721])\n",
            "tensor([0.3361, 0.1204, 0.1060])\n",
            "tensor(0.1204)\n",
            "0.12041348218917847\n",
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n",
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Everything in pytorch is based on Tensor operations.\n",
        "# A tensor can have different dimensions\n",
        "# so it can be 1d, 2d, or even 3d and higher\n",
        "\n",
        "# scalar, vector, matrix, tensor\n",
        "\n",
        "# torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) # scalar\n",
        "print(x)\n",
        "x = torch.empty(3) # vector, 1D\n",
        "print(x)\n",
        "x = torch.empty(2,3) # matrix, 2D\n",
        "print(x)\n",
        "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
        "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
        "print(x)\n",
        "\n",
        "# torch.rand(size): random numbers [0, 1]\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "\n",
        "# torch.zeros(size), fill with 0\n",
        "# torch.ones(size), fill with 1\n",
        "x = torch.zeros(5, 3)\n",
        "print(x)\n",
        "\n",
        "# check size\n",
        "print(x.size())\n",
        "\n",
        "# check data type\n",
        "print(x.dtype)\n",
        "\n",
        "# specify types, float32 default\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "# check type\n",
        "print(x.dtype)\n",
        "\n",
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x.size())\n",
        "\n",
        "# requires_grad argument\n",
        "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
        "# later in your optimization steps\n",
        "# i.e. this is a variable in your model that you want to optimize\n",
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "\n",
        "# Operations\n",
        "y = torch.rand(2, 2)\n",
        "x = torch.rand(2, 2)\n",
        "\n",
        "# elementwise addition\n",
        "z = x + y\n",
        "# torch.add(x,y)\n",
        "\n",
        "# in place addition, everythin with a trailing underscore is an inplace operation\n",
        "# i.e. it will modify the variable\n",
        "# y.add_(x)\n",
        "\n",
        "# substraction\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "\n",
        "# multiplication\n",
        "z = x * y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "# division\n",
        "z = x / y\n",
        "z = torch.div(x,y)\n",
        "\n",
        "# Slicing\n",
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:, 0]) # all rows, column 0\n",
        "print(x[1, :]) # row 1, all columns\n",
        "print(x[1,1]) # element at 1, 1\n",
        "\n",
        "# Get the actual value if only 1 element in your tensor\n",
        "print(x[1,1].item())\n",
        "\n",
        "# Reshape with torch.view()\n",
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "# if -1 it pytorch will automatically determine the necessary size\n",
        "print(x.size(), y.size(), z.size())\n",
        "\n",
        "# Numpy\n",
        "# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "# torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))\n",
        "\n",
        "# Carful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# numpy to torch with .from_numpy(x)\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# again be careful when modifying\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# by default all tensors are created on the CPU,\n",
        "# but you can also move them to the GPU (only if it's available )\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
        "    # move to CPU again\n",
        "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
        "    # z = z.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# The autograd package provides automatic differentiation\n",
        "# for all operations on Tensors\n",
        "\n",
        "# requires_grad = True -> tracks all operations on the tensor.\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(x) # created by the user -> grad_fn is None\n",
        "print(y)\n",
        "print(y.grad_fn)\n",
        "\n",
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "# Let's compute the gradients with backpropagation\n",
        "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
        "# The gradient for this tensor will be accumulated into .grad attribute.\n",
        "# It is the partial derivate of the function w.r.t. the tensor\n",
        "\n",
        "z.backward()\n",
        "print(x.grad) # dz/dx\n",
        "\n",
        "# Generally speaking, torch.autograd is an engine for computing vector-Jacobian product\n",
        "# It computes partial derivates while applying the chain rule\n",
        "\n",
        "# -------------\n",
        "# Model with non-scalar output:\n",
        "# If a Tensor is non-scalar (more than 1 elements), we need to specify arguments for backward()\n",
        "# specify a gradient argument that is a tensor of matching shape.\n",
        "# needed for vector-Jacobian product\n",
        "\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "for _ in range(10):\n",
        "    y = y * 2\n",
        "\n",
        "print(y)\n",
        "print(y.shape)\n",
        "\n",
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
        "y.backward(v)\n",
        "print(x.grad)\n",
        "\n",
        "# -------------\n",
        "# Stop a tensor from tracking history:\n",
        "# For example during our training loop when we want to update our weights\n",
        "# then this update operation should not be part of the gradient computation\n",
        "# - x.requires_grad_(False)\n",
        "# - x.detach()\n",
        "# - wrap in 'with torch.no_grad():'\n",
        "\n",
        "# .requires_grad_(...) changes an existing flag in-place.\n",
        "a = torch.randn(2, 2)\n",
        "print(a.requires_grad)\n",
        "b = ((a * 3) / (a - 1))\n",
        "print(b.grad_fn)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)\n",
        "\n",
        "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "b = a.detach()\n",
        "print(b.requires_grad)\n",
        "\n",
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)\n",
        "\n",
        "# -------------\n",
        "# backward() accumulates the gradient for this tensor into .grad attribute.\n",
        "# !!! We need to be careful during optimization !!!\n",
        "# Use .zero_() to empty the gradients before a new optimization step!\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # just a dummy example\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "\n",
        "    print(weights.grad)\n",
        "\n",
        "    # optimize model, i.e. adjust weights...\n",
        "    with torch.no_grad():\n",
        "        weights -= 0.1 * weights.grad\n",
        "\n",
        "    # this is important! It affects the final weights & output\n",
        "    weights.grad.zero_()\n",
        "\n",
        "print(weights)\n",
        "print(model_output)\n",
        "\n",
        "# Optimizer has zero_grad() method\n",
        "# optimizer = torch.optim.SGD([weights], lr=0.1)\n",
        "# During training:\n",
        "# optimizer.step()\n",
        "# optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FiqFxlTLvAW",
        "outputId": "ec56999d-17a2-4b24-b98f-16f2cf93b76b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0677, -0.2174, -0.1544], requires_grad=True)\n",
            "tensor([2.0677, 1.7826, 1.8456], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7fbcc6eef0a0>\n",
            "tensor([12.8263,  9.5332, 10.2192], grad_fn=<MulBackward0>)\n",
            "tensor(10.8595, grad_fn=<MeanBackward0>)\n",
            "tensor([4.1354, 3.5652, 3.6913])\n",
            "tensor([ 3493.4609, -2933.7319,   150.4892], grad_fn=<MulBackward0>)\n",
            "torch.Size([3])\n",
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n",
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x7fbcc6eefa00>\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\n",
            "tensor(4.8000, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass to compute loss\n",
        "y_predicted = w * x\n",
        "loss = (y_predicted - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass to compute gradient dLoss/dw\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "# update weights\n",
        "# next forward and backward pass...\n",
        "\n",
        "# continue optimizing:\n",
        "# update weights, this operation should not be part of the computational graph\n",
        "with torch.no_grad():\n",
        "    w -= 0.01 * w.grad\n",
        "# don't forget to zero the gradients\n",
        "w.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cWciIBXMBSP",
        "outputId": "171a3544-bde7-4c83-ff63-b3e665560917"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Here we replace the manually computed gradient with autograd\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    #w.data = w.data - learning_rate * w.grad\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmS8PkpFMM2p",
        "outputId": "9a51f808-101b-40fb-f01f-32e403338f71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model (input, output, forward pass with different layers)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#       - Forward = compute prediction and loss\n",
        "#       - Backward = compute gradients\n",
        "#       - Update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'#samples: {n_samples}, #features: {n_features}')\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "# Here we can use a built-in model from PyTorch\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# we can call this model with samples X\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "'''\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define diferent layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "model = LinearRegression(input_size, output_size)\n",
        "'''\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        [w, b] = model.parameters() # unpack parameters\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_cSmOwBMgtq",
        "outputId": "10a4d473-bc4f-4c7a-f2b3-464734df2c35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#samples: 4, #features: 1\n",
            "Prediction before training: f(5) = -2.481\n",
            "epoch  1 : w =  -0.3191220164299011  loss =  tensor(42.4932, grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  1.1822489500045776  loss =  tensor(1.5008, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  1.4368795156478882  loss =  tensor(0.4169, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  1.490585207939148  loss =  tensor(0.3668, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  1.5115957260131836  loss =  tensor(0.3448, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  1.5269818305969238  loss =  tensor(0.3247, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  1.54110848903656  loss =  tensor(0.3058, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  1.554688572883606  loss =  tensor(0.2880, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  1.567846417427063  loss =  tensor(0.2712, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  1.580612301826477  loss =  tensor(0.2555, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 9.159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 0) Prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "8q-_MtsUMiBX",
        "outputId": "0d525b27-9f84-4af8-d0cf-7a9cb69b94b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 3981.9082\n",
            "epoch: 20, loss = 2808.0347\n",
            "epoch: 30, loss = 2007.7690\n",
            "epoch: 40, loss = 1462.0876\n",
            "epoch: 50, loss = 1089.9237\n",
            "epoch: 60, loss = 836.0500\n",
            "epoch: 70, loss = 662.8340\n",
            "epoch: 80, loss = 544.6273\n",
            "epoch: 90, loss = 463.9447\n",
            "epoch: 100, loss = 408.8642\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 0) Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b , sigmoid at the end\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxLhTGNtNK7p",
        "outputId": "52cba3fe-6c64-4573-855f-4e0449664a3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.5190\n",
            "epoch: 20, loss = 0.4352\n",
            "epoch: 30, loss = 0.3805\n",
            "epoch: 40, loss = 0.3419\n",
            "epoch: 50, loss = 0.3131\n",
            "epoch: 60, loss = 0.2906\n",
            "epoch: 70, loss = 0.2726\n",
            "epoch: 80, loss = 0.2577\n",
            "epoch: 90, loss = 0.2451\n",
            "epoch: 100, loss = 0.2343\n",
            "accuracy: 0.9035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# gradient computation etc. not efficient for whole data set\n",
        "# -> divide dataset into small batches\n",
        "\n",
        "'''\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # loop over all batches\n",
        "    for i in range(total_batches):\n",
        "        batch_x, batch_y = ...\n",
        "'''\n",
        "\n",
        "# epoch = one forward and backward pass of ALL training samples\n",
        "# batch_size = number of training samples used in one forward/backward pass\n",
        "# number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes\n",
        "# e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch\n",
        "\n",
        "# --> DataLoader can do the batch computation for us\n",
        "\n",
        "# Implement a custom Dataset:\n",
        "# inherit Dataset\n",
        "# implement __init__ , __getitem__ , and __len__\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize data, download, etc.\n",
        "        # read with numpy or pandas\n",
        "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # here the first column is the class label, the rest are the features\n",
        "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "\n",
        "# create dataset\n",
        "dataset = WineDataset()\n",
        "\n",
        "# get first sample and unpack\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "\n",
        "# Load whole dataset with DataLoader\n",
        "# shuffle: shuffle data, good for training\n",
        "# num_workers: faster loading with multiple subprocesses\n",
        "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "features, labels = data\n",
        "print(features, labels)\n",
        "\n",
        "# Dummy Training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
        "        # Run your training process\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
        "\n",
        "# some famous datasets are available in torchvision.datasets\n",
        "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=torchvision.transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=3,\n",
        "                                           shuffle=True)\n",
        "\n",
        "# look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "inputs, targets = data\n",
        "print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "id": "jHhzoMzMTHmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n",
        "during creation of the DataSet\n",
        "\n",
        "complete list of built-in transforms:\n",
        "https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "\n",
        "On Images\n",
        "---------\n",
        "CenterCrop, Grayscale, Pad, RandomAffine\n",
        "RandomCrop, RandomHorizontalFlip, RandomRotation\n",
        "Resize, Scale\n",
        "\n",
        "On Tensors\n",
        "----------\n",
        "LinearTransformation, Normalize, RandomErasing\n",
        "\n",
        "Conversion\n",
        "----------\n",
        "ToPILImage: from tensor or ndrarray\n",
        "ToTensor : from numpy.ndarray or PILImage\n",
        "\n",
        "Generic\n",
        "-------\n",
        "Use Lambda\n",
        "\n",
        "Custom\n",
        "------\n",
        "Write own class\n",
        "\n",
        "Compose multiple Transforms\n",
        "---------------------------\n",
        "composed = transforms.Compose([Rescale(256),\n",
        "                               RandomCrop(224)])\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self, transform=None):\n",
        "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # note that we do not convert to tensor here\n",
        "        self.x_data = xy[:, 1:]\n",
        "        self.y_data = xy[:, [0]]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.x_data[index], self.y_data[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "# Custom Transforms\n",
        "# implement __call__(self, sample)\n",
        "class ToTensor:\n",
        "    # Convert ndarrays to Tensors\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "    # multiply inputs with a given factor\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        inputs *= self.factor\n",
        "        return inputs, targets\n",
        "\n",
        "print('Without Transform')\n",
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor Transform')\n",
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor and Multiplication Transform')\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)"
      ],
      "metadata": {
        "id": "E6aWLFtKTPV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "#\n",
        "#        -> 2.0              -> 0.65\n",
        "# Linear -> 1.0  -> Softmax  -> 0.25   -> CrossEntropy(y, y_hat)\n",
        "#        -> 0.1              -> 0.1\n",
        "#\n",
        "#     scores(logits)      probabilities\n",
        "#                           sum = 1.0\n",
        "#\n",
        "\n",
        "# Softmax applies the exponential function to each element, and normalizes\n",
        "# by dividing by the sum of all these exponentials\n",
        "# -> squashes the output to be between 0 and 1 = probability\n",
        "# sum of all probabilities is 1\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy:', outputs)\n",
        "\n",
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0) # along values along first axis\n",
        "print('softmax torch:', outputs)\n",
        "\n",
        "# Cross entropy\n",
        "# Cross-entropy loss, or log loss, measures the performance of a classification model\n",
        "# whose output is a probability value between 0 and 1.\n",
        "# -> loss increases as the predicted probability diverges from the actual label\n",
        "def cross_entropy(actual, predicted):\n",
        "    EPS = 1e-15\n",
        "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss # / float(predicted.shape[0])\n",
        "\n",
        "# y must be one hot encoded\n",
        "# if class 0: [1 0 0]\n",
        "# if class 1: [0 1 0]\n",
        "# if class 2: [0 0 1]\n",
        "Y = np.array([1, 0, 0])\n",
        "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "l1 = cross_entropy(Y, Y_pred_good)\n",
        "l2 = cross_entropy(Y, Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}')\n",
        "\n",
        "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
        "# nn.LogSoftmax + nn.NLLLoss\n",
        "# NLLLoss = negative log likelihood loss\n",
        "loss = nn.CrossEntropyLoss()\n",
        "# loss(input, target)\n",
        "\n",
        "# target is of size nSamples = 1\n",
        "# each element has class label: 0, 1, or 2\n",
        "# Y (=target) contains class labels, not one-hot\n",
        "Y = torch.tensor([0])\n",
        "\n",
        "# input is of size nSamples x nClasses = 1 x 3\n",
        "# y_pred (=input) must be raw, unnormalizes scores (logits) for each class, not softmax\n",
        "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
        "print(f'PyTorch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')\n",
        "\n",
        "# allows batch loss for multiple samples\n",
        "\n",
        "# target is of size nBatch = 3\n",
        "# each element has class label: 0, 1, or 2\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "\n",
        "# input is of size nBatch x nClasses = 3 x 3\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred_good = torch.tensor(\n",
        "    [[0.1, 0.2, 3.9], # predict class 2\n",
        "    [1.2, 0.1, 0.3], # predict class 0\n",
        "    [0.3, 2.2, 0.2]]) # predict class 1\n",
        "\n",
        "Y_pred_bad = torch.tensor(\n",
        "    [[0.9, 0.2, 0.1],\n",
        "    [0.1, 0.3, 1.5],\n",
        "    [1.2, 0.2, 0.5]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "print(f'Batch Loss1:  {l1.item():.4f}')\n",
        "print(f'Batch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')\n",
        "\n",
        "# Binary classification\n",
        "class NeuralNet1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet1, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # sigmoid at the end\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Multiclass problem\n",
        "class NeuralNet2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet2, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss()  # (applies Softmax)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOFrf-ihTWwS",
        "outputId": "aa929ae5-3d76-4c69-ff75-5076a3723f08"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
            "softmax torch: tensor([0.6590, 0.2424, 0.0986])\n",
            "Loss1 numpy: 0.3567\n",
            "Loss2 numpy: 2.3026\n",
            "PyTorch Loss1: 0.4170\n",
            "PyTorch Loss2: 1.8406\n",
            "Actual class: 0, Y_pred1: 0, Y_pred2: 1\n",
            "Batch Loss1:  0.2834\n",
            "Batch Loss2: 1.6418\n",
            "Actual class: tensor([2, 0, 1]), Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output = w*x + b\n",
        "# output = activation_function(output)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])\n",
        "\n",
        "# sofmax\n",
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)\n",
        "\n",
        "# sigmoid\n",
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)\n",
        "\n",
        "#tanh\n",
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)\n",
        "\n",
        "# relu\n",
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)\n",
        "\n",
        "# leaky relu\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)\n",
        "\n",
        "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
        "#torch.relu on the other side is just the functional API call to the relu function,\n",
        "#so that you can add it e.g. in your forward method yourself.\n",
        "\n",
        "# option 1 (create nn modules)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# option 2 (use activation functions directly in forward pass)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.linear1(x))\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "        return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nEeAch_Ta4Z",
        "outputId": "1842b7fa-a1e6-469e-a08c-8817f7275a9c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output = w*x + b\n",
        "# output = activation_function(output)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])\n",
        "\n",
        "# sofmax\n",
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)\n",
        "\n",
        "# sigmoid\n",
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)\n",
        "\n",
        "#tanh\n",
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)\n",
        "\n",
        "# relu\n",
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)\n",
        "\n",
        "# leaky relu\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)\n",
        "\n",
        "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
        "#torch.relu on the other side is just the functional API call to the relu function,\n",
        "#so that you can add it e.g. in your forward method yourself.\n",
        "\n",
        "# option 1 (create nn modules)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# option 2 (use activation functions directly in forward pass)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.linear1(x))\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "        return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypd1rx3ETeK3",
        "outputId": "f87183d5-7714-4545-bd13-672d6db9acc0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "vAgzMU8oT5WQ",
        "outputId": "5749bac8-1b9d-40a5-efd5-5847b76c3f63"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 93297528.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 71382259.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 26917519.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 1866783.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.4063\n",
            "Epoch [1/2], Step [200/600], Loss: 0.1389\n",
            "Epoch [1/2], Step [300/600], Loss: 0.1679\n",
            "Epoch [1/2], Step [400/600], Loss: 0.2562\n",
            "Epoch [1/2], Step [500/600], Loss: 0.1534\n",
            "Epoch [1/2], Step [600/600], Loss: 0.0886\n",
            "Epoch [2/2], Step [100/600], Loss: 0.0561\n",
            "Epoch [2/2], Step [200/600], Loss: 0.1153\n",
            "Epoch [2/2], Step [300/600], Loss: 0.1010\n",
            "Epoch [2/2], Step [400/600], Loss: 0.0819\n",
            "Epoch [2/2], Step [500/600], Loss: 0.0633\n",
            "Epoch [2/2], Step [600/600], Loss: 0.0768\n",
            "Accuracy of the network on the 10000 test images: 97.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 5\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
        "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
        "        x = F.relu(self.fc1(x))               # -> n, 120\n",
        "        x = F.relu(self.fc2(x))               # -> n, 84\n",
        "        x = self.fc3(x)                       # -> n, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "id": "y-GV7QN-UAKc",
        "outputId": "ace1890d-0540-4e68-875b-654a04b3e833"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 32701499.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [2000/12500], Loss: 2.3065\n",
            "Epoch [1/5], Step [4000/12500], Loss: 2.3016\n",
            "Epoch [1/5], Step [6000/12500], Loss: 2.2992\n",
            "Epoch [1/5], Step [8000/12500], Loss: 2.2757\n",
            "Epoch [1/5], Step [10000/12500], Loss: 2.2606\n",
            "Epoch [1/5], Step [12000/12500], Loss: 2.0003\n",
            "Epoch [2/5], Step [2000/12500], Loss: 2.3148\n",
            "Epoch [2/5], Step [4000/12500], Loss: 3.0208\n",
            "Epoch [2/5], Step [6000/12500], Loss: 1.9173\n",
            "Epoch [2/5], Step [8000/12500], Loss: 2.6578\n",
            "Epoch [2/5], Step [10000/12500], Loss: 2.0586\n",
            "Epoch [2/5], Step [12000/12500], Loss: 1.3968\n",
            "Epoch [3/5], Step [2000/12500], Loss: 1.4033\n",
            "Epoch [3/5], Step [4000/12500], Loss: 1.3589\n",
            "Epoch [3/5], Step [6000/12500], Loss: 1.5702\n",
            "Epoch [3/5], Step [8000/12500], Loss: 1.8939\n",
            "Epoch [3/5], Step [10000/12500], Loss: 2.0498\n",
            "Epoch [3/5], Step [12000/12500], Loss: 1.2808\n",
            "Epoch [4/5], Step [2000/12500], Loss: 1.9686\n",
            "Epoch [4/5], Step [4000/12500], Loss: 2.5718\n",
            "Epoch [4/5], Step [6000/12500], Loss: 1.7862\n",
            "Epoch [4/5], Step [8000/12500], Loss: 0.9181\n",
            "Epoch [4/5], Step [10000/12500], Loss: 0.9227\n",
            "Epoch [4/5], Step [12000/12500], Loss: 2.4598\n",
            "Epoch [5/5], Step [2000/12500], Loss: 1.4159\n",
            "Epoch [5/5], Step [4000/12500], Loss: 1.9158\n",
            "Epoch [5/5], Step [6000/12500], Loss: 1.6205\n",
            "Epoch [5/5], Step [8000/12500], Loss: 1.2175\n",
            "Epoch [5/5], Step [10000/12500], Loss: 2.0428\n",
            "Epoch [5/5], Step [12000/12500], Loss: 0.9768\n",
            "Finished Training\n",
            "Accuracy of the network: 48.63 %\n",
            "Accuracy of plane: 51.7 %\n",
            "Accuracy of car: 73.3 %\n",
            "Accuracy of bird: 25.0 %\n",
            "Accuracy of cat: 25.7 %\n",
            "Accuracy of deer: 39.6 %\n",
            "Accuracy of dog: 36.5 %\n",
            "Accuracy of frog: 64.6 %\n",
            "Accuracy of horse: 53.2 %\n",
            "Accuracy of ship: 64.9 %\n",
            "Accuracy of truck: 51.8 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "mean = np.array([0.5, 0.5, 0.5])\n",
        "std = np.array([0.25, 0.25, 0.25])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'data/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(class_names)\n",
        "\n",
        "\n",
        "def imshow(inp, title):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "\n",
        "#### Finetuning the convnet ####\n",
        "# Load a pretrained model and reset final fully connected layer.\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "# Learning rate scheduling should be applied after optimizer’s update\n",
        "# e.g., you should write your code this way:\n",
        "# for epoch in range(100):\n",
        "#     train(...)\n",
        "#     validate(...)\n",
        "#     scheduler.step()\n",
        "\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n",
        "\n",
        "\n",
        "#### ConvNet as fixed feature extractor ####\n",
        "# Here, we need to freeze all the network except the final layer.\n",
        "# We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ],
      "metadata": {
        "id": "hfFRP8yHUUkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/mnist1')\n",
        "###################################################\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "#plt.show()\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "img_grid = torchvision.utils.make_grid(example_data)\n",
        "writer.add_image('mnist_images', img_grid)\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "writer.add_graph(model, example_data.reshape(-1, 28*28).to(device))\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Train the model\n",
        "running_loss = 0.0\n",
        "running_correct = 0\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        running_correct += (predicted == labels).sum().item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "            ############## TENSORBOARD ########################\n",
        "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
        "            running_accuracy = running_correct / 100 / predicted.size(0)\n",
        "            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
        "            running_correct = 0\n",
        "            running_loss = 0.0\n",
        "            ###################################################\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "class_labels = []\n",
        "class_preds = []\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        values, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\n",
        "\n",
        "        class_preds.append(class_probs_batch)\n",
        "        class_labels.append(labels)\n",
        "\n",
        "    # 10000, 10, and 10000, 1\n",
        "    # stack concatenates tensors along a new dimension\n",
        "    # cat concatenates tensors in the given dimension\n",
        "    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\n",
        "    class_labels = torch.cat(class_labels)\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
        "\n",
        "    ############## TENSORBOARD ########################\n",
        "    classes = range(10)\n",
        "    for i in classes:\n",
        "        labels_i = class_labels == i\n",
        "        preds_i = class_preds[:, i]\n",
        "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
        "        writer.close()\n",
        "    ###################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "K_owBOr_UWnx",
        "outputId": "114be83f-5b56-4ca1-ba8d-871874f7f41e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [100/938], Loss: 0.1947\n",
            "Epoch [1/1], Step [200/938], Loss: 0.2292\n",
            "Epoch [1/1], Step [300/938], Loss: 0.3371\n",
            "Epoch [1/1], Step [400/938], Loss: 0.1217\n",
            "Epoch [1/1], Step [500/938], Loss: 0.1683\n",
            "Epoch [1/1], Step [600/938], Loss: 0.0780\n",
            "Epoch [1/1], Step [700/938], Loss: 0.1251\n",
            "Epoch [1/1], Step [800/938], Loss: 0.1437\n",
            "Epoch [1/1], Step [900/938], Loss: 0.1512\n",
            "Accuracy of the network on the 10000 test images: 96.15 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "''' 3 DIFFERENT METHODS TO REMEMBER:\n",
        " - torch.save(arg, PATH) # can be model, tensor, or dictionary\n",
        " - torch.load(PATH)\n",
        " - torch.load_state_dict(arg)\n",
        "'''\n",
        "\n",
        "''' 2 DIFFERENT WAYS OF SAVING\n",
        "# 1) lazy way: save whole model\n",
        "torch.save(model, PATH)\n",
        "\n",
        "# model class must be defined somewhere\n",
        "model = torch.load(PATH)\n",
        "model.eval()\n",
        "\n",
        "# 2) recommended way: save only the state_dict\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "# model must be created again with parameters\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()\n",
        "'''\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "# train your model...\n",
        "\n",
        "####################save all ######################################\n",
        "for param in model.parameters():\n",
        "    print(param)\n",
        "\n",
        "# save and load entire model\n",
        "\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model, FILE)\n",
        "\n",
        "loaded_model = torch.load(FILE)\n",
        "loaded_model.eval()\n",
        "\n",
        "for param in loaded_model.parameters():\n",
        "    print(param)\n",
        "\n",
        "\n",
        "############save only state dict #########################\n",
        "\n",
        "# save only state dict\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model.state_dict(), FILE)\n",
        "\n",
        "print(model.state_dict())\n",
        "loaded_model = Model(n_input_features=6)\n",
        "loaded_model.load_state_dict(torch.load(FILE)) # it takes the loaded dictionary, not the path file itself\n",
        "loaded_model.eval()\n",
        "\n",
        "print(loaded_model.state_dict())\n",
        "\n",
        "\n",
        "###########load checkpoint#####################\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "checkpoint = {\n",
        "\"epoch\": 90,\n",
        "\"model_state\": model.state_dict(),\n",
        "\"optim_state\": optimizer.state_dict()\n",
        "}\n",
        "print(optimizer.state_dict())\n",
        "FILE = \"checkpoint.pth\"\n",
        "torch.save(checkpoint, FILE)\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
        "\n",
        "checkpoint = torch.load(FILE)\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "# model.train()\n",
        "\n",
        "print(optimizer.state_dict())\n",
        "\n",
        "# Remember that you must call model.eval() to set dropout and batch normalization layers\n",
        "# to evaluation mode before running inference. Failing to do this will yield\n",
        "# inconsistent inference results. If you wish to resuming training,\n",
        "# call model.train() to ensure these layers are in training mode.\n",
        "\n",
        "\"\"\" SAVING ON GPU/CPU\n",
        "\n",
        "# 1) Save on GPU, Load on CPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device('cpu')\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))\n",
        "\n",
        "# 2) Save on GPU, Load on GPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.to(device)\n",
        "\n",
        "# Note: Be sure to use the .to(torch.device('cuda')) function\n",
        "# on all model inputs, too!\n",
        "\n",
        "# 3) Save on CPU, Load on GPU\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
        "model.to(device)\n",
        "\n",
        "# This loads the model to a given GPU device.\n",
        "# Next, be sure to call model.to(torch.device('cuda')) to convert the model’s parameter tensors to CUDA tensors\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "DM6EQK5VUZ0q",
        "outputId": "b4a19984-f0fa-42ea-ff12-d66a51348924"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.1005,  0.3783,  0.1288, -0.0911, -0.1582, -0.0144]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.1628], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.1005,  0.3783,  0.1288, -0.0911, -0.1582, -0.0144]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.1628], requires_grad=True)\n",
            "OrderedDict([('linear.weight', tensor([[ 0.1005,  0.3783,  0.1288, -0.0911, -0.1582, -0.0144]])), ('linear.bias', tensor([0.1628]))])\n",
            "OrderedDict([('linear.weight', tensor([[ 0.1005,  0.3783,  0.1288, -0.0911, -0.1582, -0.0144]])), ('linear.bias', tensor([0.1628]))])\n",
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n",
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' SAVING ON GPU/CPU \\n\\n# 1) Save on GPU, Load on CPU\\ndevice = torch.device(\"cuda\")\\nmodel.to(device)\\ntorch.save(model.state_dict(), PATH)\\n\\ndevice = torch.device(\\'cpu\\')\\nmodel = Model(*args, **kwargs)\\nmodel.load_state_dict(torch.load(PATH, map_location=device))\\n\\n# 2) Save on GPU, Load on GPU\\ndevice = torch.device(\"cuda\")\\nmodel.to(device)\\ntorch.save(model.state_dict(), PATH)\\n\\nmodel = Model(*args, **kwargs)\\nmodel.load_state_dict(torch.load(PATH))\\nmodel.to(device)\\n\\n# Note: Be sure to use the .to(torch.device(\\'cuda\\')) function \\n# on all model inputs, too!\\n\\n# 3) Save on CPU, Load on GPU\\ntorch.save(model.state_dict(), PATH)\\n\\ndevice = torch.device(\"cuda\")\\nmodel = Model(*args, **kwargs)\\nmodel.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\\nmodel.to(device)\\n\\n# This loads the model to a given GPU device. \\n# Next, be sure to call model.to(torch.device(\\'cuda\\')) to convert the model’s parameter tensors to CUDA tensors\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}